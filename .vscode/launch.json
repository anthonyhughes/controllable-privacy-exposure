{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Mimic Data",
            "type": "debugpy",
            "request": "launch",
            "program": "mimic/mimic_data.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--flag", "test"
            ],
        },
        {
            "name": "Pseudonymizer",
            "type": "debugpy",
            "request": "launch",
            "program": "pseudonymizer/pseudonymize.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                // "--task", "legal_court",
                // "--task", "cnn",
                "--task", "discharge_instructions",
                "--plib", "spacy",
            ],
        },
        {
            "name": "Build Training Data",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/data_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--flag", "training"
                // "--flag", "test"
            ],
        },
        {
            "name": "Output Training Data",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/data_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--flag", "training"
            ],
        },
        {
            "name": "Stats",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/stats_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
        },
        {
            "name": "OpenAI Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/openai_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--task", "cnn",
                "--model", "gpt-4o-mini",
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "OpenAI Batch Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/openai_batch_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                // "--task", "legal_court",
                // "--task", "cnn",
                // "--task", "discharge_instructions",
                "--task", "brief_hospital_course",
                "--model", "gpt-4o-mini",
                "--flag", "batch"
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "OpenAI Check Batch Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/openai_batch_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--task", "legal_court",
                "--model", "gpt-4o-mini",
                "--flag", "check",
                "--job_id", "batch_66f69f4c9d748190aa798ad9c60b2be9"
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "OpenAI Cancel Batch Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/openai_batch_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--task", "legal_court",
                "--model", "gpt-4o-mini",
                "--flag", "cancel",
                "--job_id", "batch_66f693e83b7881909e632b7c81f5ad97"
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "OpenAI Retrieve Batch Results Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/openai_batch_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--task", "cnn",
                "--model", "gpt-4o-mini",
                "--flag", "retrieve",
                "--file_id", "file-wPRjmlZ5YfwzZvserABumhbP"
            ],
            "envFile": "${workspaceFolder}/.env"
        },        
        {
            "name": "Claude Sonnet Batch Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/aws_bedrock_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--file_id", "tpm",
                "--flag", "create-batch",
                "--task", "discharge_instructions",
                "--model", "Meta-Llama-3.1-70B-Instruct-bnb-4bit",
                // "--model", "llama-3-8b-Instruct-bnb-4bit",
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "Claude Sonnet Retrieve Batch Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/aws_bedrock_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--file_id", "Meta-Llama-3.1-70B-Instruct-bnb-4bit-1728032671.196179.jsonl.out",
                "--flag", "retrieve",
                "--task", "discharge_instructions",
                "--model", "Meta-Llama-3.1-70B-Instruct-bnb-4bit",
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "Unsloth Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/unsloth_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}",
                "CUDA_VISIBLE_DEVICES": "1"
            },
            "args": [
                "--task", "legal_court",
                "--model", "mistral-7b-instruct-v0.3-bnb-4bit",
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "Unsloth Fine-tune Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/unsloth_ft_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}",
                "CUDA_VISIBLE_DEVICES": "0"
            },
            "args": [
                "--model", "Meta-Llama-3.1-70B-Instruct-bnb-4bit",
                "--training_data_file", "training_data-v6.csv",
            ],
            "envFile": "${workspaceFolder}/.env"
        },
        {
            "name": "Utility Eval Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/eval_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                // "--tasks", "legal_court",
                "--sub_tasks", "_sani_summ",
                // "--tasks", "legal_court",
                "--tasks", "cnn",

                // "--model", "llama-3-8b-Instruct-bnb-4bit",
                // "--model", "gpt-4o-mini",
                // "--model", "Meta-Llama-3.1-70B-Instruct-bnb-4bit",
                "--model", "claude-3-5-sonnet-20240620",                
                
                "--eval_type", "utility"
            ],
        },
        {
            "name": "Privacy Eval Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/eval_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                // "--model", "llama-3-8b-Instruct-bnb-4bit",
                // "--model", "mistral-7b-instruct-v0.3-bnb-4bit",
                // "--model", "claude-3-5-sonnet-20240620",
                "--tasks", "all",
                "--sub_tasks", "all",                
                "--model", "mistralymous-7b-bnb-4bit",
                "--eval_type", "privacy"
            ],
        },
        {
            "name": "Reidentif Eval Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/eval_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                // "--model", "claude-3-5-sonnet-20240620",
                // "--model", "gpt-4o-mini",
                // "--model", "mistral-7b-instruct-v0.3-bnb-4bit",
                // "--model", "llama-3-8b-Instruct-bnb-4bit",
                // "--model", "Meta-Llama-3.1-70B-Instruct-bnb-4bit",

                "--model", "llamonymous-3-8b-bnb-4bit",
                // "--model", "mistralymous-7b-bnb-4bit",

                // "--sanitized_input_file", "claude-3-5-sonnet-20240620-2024-10-07-06-14-44.json", 
                // "--sanitized_input_file", "gpt-4o-mini-2024-10-07-17-36-02.json",
                // "--sanitized_input_file", "mistral-7b-instruct-v0.3-bnb-4bit-2024-10-07-18-10-03.json",
                // "--sanitized_input_file", "llama-3-8b-Instruct-bnb-4bit-2024-10-07-23-06-53.json",
                // "--sanitized_input_file", "Meta-Llama-3.1-70B-Instruct-bnb-4bit-2024-10-07-10-04-29.json",

                "--sanitized_input_file", "llamonymous-3-8b-bnb-4bit-2024-10-27-09-18-36.json",
                // "--sanitized_input_file", "mistralymous-7b-bnb-4bit-2024-10-27-09-20-45.json",


                // "--sanitized_summaries_file", "claude-3-5-sonnet-20240620-2024-10-07-06-14-44.json",
                // "--sanitized_summaries_file", "gpt-4o-mini-2024-10-07-17-36-01.json",
                // "--sanitized_summaries_file", "mistral-7b-instruct-v0.3-bnb-4bit-2024-10-03-20-56-01.json",
                // "--sanitized_summaries_file", "llama-3-8b-Instruct-bnb-4bit-2024-10-07-23-06-52.json",
                // "--sanitized_summaries_file", "Meta-Llama-3.1-70B-Instruct-bnb-4bit-2024-10-07-10-04-28.json",
                
                "--sanitized_summaries_file", "llamonymous-3-8b-bnb-4bit-2024-10-27-09-18-36.json",
                // "--sanitized_summaries_file", "mistralymous-7b-bnb-4bit-2024-10-27-09-20-45.json",

                "--eval_type", "reidentification",
                "--sub_tasks", "all",
                "--tasks", "all",
            ],
        },
        {
            "name": "Reidentif Graph Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/eval_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                "--tasks", "all",
                "--model", "all",
                "--eval_type", "graph",
                "--sub_tasks", "_sani_summ",
                // "--file_id", "mistral-7b-instruct-v0.3-bnb-4bit-2024-10-03-20-56-01.json"
                "--file_id", "Meta-Llama-3.1-70B-Instruct-bnb-4bit-reidentification_results-20241008-092100.json"
            ],
        },
        {
            "name": "Statistical Pipeline",
            "type": "debugpy",
            "request": "launch",
            "program": "pipelines/statistical_testing_pipeline.py",
            "console": "integratedTerminal",
            "cwd": "${workspaceFolder}",
            "env": {
                "PYTHONPATH": "${cwd}"
            },
            "args": [
                // "--tasks", "all",
                "--model", "claude-3-5-sonnet-20240620",
                // "--model", "gpt-4o-mini",
                // "--model", "mistral-7b-instruct-v0.3-bnb-4bit",
                // "--model", "llama-3-8b-Instruct-bnb-4bit",
                // "--model", "Meta-Llama-3.1-70B-Instruct-bnb-4bit",

            ],
        }
    ]
}